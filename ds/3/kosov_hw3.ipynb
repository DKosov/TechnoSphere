{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Алгоритмы интеллектуальной обработки больших объемов данных\n",
    "## Домашнее задание №3: Линейные модели\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### <hr\\>\n",
    "**Общая информация**\n",
    "\n",
    "**Срок сдачи:** 17 ноября 2018, 06:00 <br\\>\n",
    "**Штраф за опоздание:** -2 балла после 06:00 17 ноября, -4 балла после 06:00 24 ноября, -6 баллов после 06:00 1 декабря, -8 баллов после 06:00 8 декабря.\n",
    "\n",
    "При отправлении ДЗ указывайте фамилию в названии файла<br\\>\n",
    "\n",
    "Используйте данный Ipython Notebook при оформлении домашнего задания.\n",
    "\n",
    "**Штрафные баллы:**\n",
    "\n",
    "1. Невыполнение PEP8 -1 балл\n",
    "2. Отсутствие фамилии в имени скрипта (скрипт должен называться по аналогии со stroykova_hw2.ipynb) -1 балл\n",
    "3. Все строчки должны быть выполнены. Нужно, чтобы output команды можно было увидеть уже в git'е. В противном случае -1 балл\n",
    "4. При оформлении ДЗ нужно пользоваться данным файлом в качестве шаблона. Не нужно удалять и видоизменять написанный код и текст, если явно не указана такая возможность. В противном случае -1 балл\n",
    "<hr\\>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams['figure.figsize'] = (12,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Определям, что вам досталось"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src='https://static1.squarespace.com/static/571a6e39b6aa608067028725/t/577988518419c2d62fb5922f/1467582555915/'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Укажите свою фамилию на русском языке в поле ниже."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Имплементируйте обучение логистической регрессии с L2 регуляризацией с помощью метода  Stochastic Gradient Descent (SGD)\n"
     ]
    }
   ],
   "source": [
    "USER_NAME = u\"Косов\".lower()\n",
    "REGULARIZATIONS = [\"L1\", \"L2\"]\n",
    "ALGORITHM = [\"\", \"Mini Batch\"]\n",
    "\n",
    "print (\"Имплементируйте обучение логистической регрессии с %s регуляризацией с помощью метода %s Stochastic Gradient Descent (SGD)\"\\\n",
    "% (\n",
    "    REGULARIZATIONS[hash(USER_NAME) % 2],\n",
    "    ALGORITHM[hash(USER_NAME[::-1]) % 2]\n",
    ") )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Теоретическое введение\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** Что почитать по теории ***\n",
    "\n",
    "Одна из лучших книг по ML $-$ \"Pattern Recognition and Machine Learning\" Bishop, Christopher. Логистическая регрессия в ней в параграфе 4.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Логистическая регрессия является линейным классификатором, который оптимизирует так называемый функционал log loss:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$L(w) = - \\frac{1}{N}\\left[\\sum_i y_i \\log a_i + ( 1 - y_i) \\log (1 - a_i) \\right],$$\n",
    "где  $y_i  \\in \\{0,1\\}$ $-$ метка класса, $a_i$ $-$ предсказание алгоритма на объекте $x_i$. Модель пытается предсказать апостериорую вероятность объекта принадлежать к классу \"1\":\n",
    "$$ p(y_i = 1 | x_i) = a(x_i) =  \\sigma( \\langle\\,x_i,w\\rangle ),$$\n",
    "где $w$ $-$ вектор весов (размерности $D$), $x_i$ $-$ вектор признаков (такой же размерности $D$).\n",
    "\n",
    "Функция $\\sigma(x)$ $-$ нелинейная функция, пероводящее скалярное произведение объекта на веса в число $\\in (0,1)$ (мы же моделируем вероятность все-таки!)\n",
    "\n",
    "$$\\sigma(x) = \\frac{1}{1 + \\exp(-x)}$$\n",
    "\n",
    "Если внимательно посмотреть на функцию потерь, то можно заметить, что в зависимости от правильного ответа алгоритм штрафуется или функцией $-\\log a_i$, или функцией $-\\log (1 - a_i)$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Часто для решения проблем, которые так или иначе связаны с проблемой переобучения, в функционал качества добавляют слагаемое, которое называют ***регуляризацией***. Итоговый функционал тогда принимает вид:\n",
    "$$L(w) = - \\frac{1}{N}\\left[\\sum_i y_i \\log a_i + ( 1 - y_i) \\log (1 - a_i) \\right] +  \\frac{1}{C}R(w)$$\n",
    "\n",
    "Самое понятие регуляризации введено основателем ВМК академиком Тихоновым https://ru.wikipedia.org/wiki/Метод_регуляризации_Тихонова\n",
    "\n",
    "Идейно методика регуляризации заключается в следующем $-$ мы рассматриваем некорректно поставленную задачу (что это такое можно найти в интернете), для того чтобы сузить набор различных вариантов (лучшие из которых будут являться переобучением ) мы вводим дополнительные ограничения на множество искомых решений. На лекции Вы уже рассмотрели два варианта регуляризации.\n",
    "\n",
    "$L1$ регуляризация:\n",
    "$$R(w) = \\sum_{j=1}^{D}|w_j|$$\n",
    "$L2$ регуляризация:\n",
    "$$R(w) =  \\sum_{j=1}^{D}w_j^2$$\n",
    "\n",
    "С их помощью мы ограничиваем модель в  возможности выбора каких угодно весов минимизирующих наш лосс, модель уже не сможет подстроиться под данные как ей угодно. \n",
    "\n",
    "Вам нужно добавить соотвествущую Вашему варианту регуляризацию в функцию потерь.\n",
    "\n",
    "И так, мы поняли, какую функцию ошибки будем минимизировать, разобрались, как получить предсказания по объекту и обученным весам. Осталось разобраться, как получить оптимальные веса. Для этого нужно выбрать какой-то метод оптимизации. Отметим, что вне зависимости от алгоритма оптимизации, данная модель все равно будет называться ***логистической регрессией***.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Градиентный спуск является самым популярным алгоритмом обучения линейных моделей. В этом задании Вам предложат реализовать стохастический градиентный спуск или  мини-батч градиентный спуск (мини-батч на русский язык довольно сложно перевести, многие переводят это как \"пакетный\", но мне не кажется этот перевод удачным). Далее нам потребуется определение **эпохи**.\n",
    "Эпохой в SGD и MB-GD называется один проход по **всем** объектам в обучающей выборки.\n",
    "* В SGD градиент расчитывается по одному случайному объекту. Сам алгоритм выглядит примерно так:\n",
    "        1) Перемешать выборку\n",
    "        2) Посчитать градиент функции потерь на одном объекте (далее один объект тоже будем называть батчем)\n",
    "        3) Сделать шаг спуска\n",
    "        4) Повторять 2) и 3) пока не пройдет максимальное число эпох.\n",
    "* В Mini Batch SGD - по подвыборке объектов. Сам алгоритм выглядит примерно так::\n",
    "        1) Перемешать выборку\n",
    "        2) Почитать градиент функции потерь по мини-батчу (не забыть поделить на  число объектов в мини-батче)\n",
    "        3) Сделать шаг спуска\n",
    "        4) Повторять 2) и 3) пока не пройдет максимальное число эпох.\n",
    "* Для отладки алгоритма реализуйте возможность  вывода средней ошибки на обучении модели по объектам (мини-батчам). После шага градиентного спуска посчитайте значение ошибки на объекте (или мини-батче), а затем усредните, например, по ста шагам. Если обучение проходит корректно, то мы должны увидеть, что каждые 100 шагов функция потерь уменьшается. \n",
    "* Правило останова - максимальное количество эпох\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Примечание для случая L1-регуляризации:\n",
    "\n",
    "При расчете производной по функции потерь c L1-регуляризацией  могут возникнуть сомнения по поводу производной части с модулями. \n",
    "\n",
    "Вам на выбор предлагаются следующией варианты:\n",
    "* Считать субградиент $\\partial|w_j| = sign(w_j)$ (проще, но с большой вероятностью не приведет к занулению коэффициентов)\n",
    "* Метод SGD-Clipping из [статьи](https://www.aclweb.org/anthology/P/P09/P09-1054.pdf) - раздел 3.1, страница 479, правая колонка снизу (чуть сложнее, но зато должно занулять)\n",
    "* Cumulative Penalty из той же [статьи](https://www.aclweb.org/anthology/P/P09/P09-1054.pdf) - раздел 3.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Теоретические вопросы (2 балла)\n",
    "В этой части Вам будут предложены теоретичские вопросы и задачи по теме. Вы, конечно, можете списать их у своего товарища или найти решение в интернете, но учтите, что они обязательно войдут в теоретический коллоквиум. Лучше разобраться в теме сейчас и успешно ответить на коллоквиуме, чем списать, не разобравшись в материале, и быть терзаемым совестью. \n",
    "\n",
    "\n",
    "Формулы надо оформлять в формате **LaTeX**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задача 1. Градиент для логистической регрессии.\n",
    "* Посчитайте градиент функции потерь по весам для модели логистической регрессии с конкретно Вашей регуляризацией:\n",
    "\n",
    "$$ \\nabla_w L = \\dots $$\n",
    "\n",
    " Отнеситесь к этому пункту максимально серьезно, этот градиент Вам нужно будет реализовать в задании."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Ваше решение здесь***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " $$\\frac{dL}{dw^k} = \\frac{1}{N}\\sum_i x_{i}^k(a_i-y_i)  +  \\frac{2}{C}w^k$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задача 2. Анализ поведения градиента.\n",
    "\n",
    "Посчитав формулу градиента, подумайте, как будут меняться веса в зависимости  от \"вида\" ошибки: \n",
    "* Если правильный ответ был  класс \"1\", а значение $a(x_i)$ близко к нулю, после шага градиентного спуска веса в среднем увеличатся или уменьшатся?\n",
    "\n",
    "* Если правильный ответ был  класс \"0\", а значение $a(x_i)$ близко к  единице, после шага градиентного спуска веса в среднем увеличатся или уменьшатся?\n",
    "\n",
    "Вам такое поведение кажется логичным?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Ваше решение здесь***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ w_i = w_{i-1}-\\eta_k\\nabla_wL(w_{i-1}) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ w_i^k = w_{i-1}^k-\\eta_k\\left[\\frac{1}{N}\\sum_i x_{i}^k(a_i-y_i)  +  \\frac{2}{C}w^k_{i-1}\\right]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ w_i^k = w_{i-1}^k(1-2\\frac{\\eta_k}{C})+\\frac{\\eta_k}{N}\\sum_i x_i^k$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "в предположении, что признаки неотрицательны:\n",
    "1. веса не уменьшаются\n",
    "2. веса не увеличиваются"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задача 3. Сравнение с линейной регрессией.\n",
    "\n",
    "Как было рассказано на лекции, функция потерь линейной регрессии без регуляризации имеет вид:\n",
    "$$ L( w ) = \\frac{1}{N}\\left[\\sum_i (a(x_i) - y_i)^2 \\right] $$\n",
    "где $a(x_i)$ предсказания модели на $i$ объекте, $y_i$ $-$ значение целовой переменной на $i$ объекте, $N$ $-$ размер выборки.\n",
    "$a(x_i)$ через веса и признаки вычисляется как:\n",
    "$$ a(x_i) =  \\langle\\,x_i,w\\rangle $$\n",
    "где $x_i$ $-$ вектор признаков, $w$ $-$ вектор весов модели.\n",
    "* Посчитайте градиент  функции потерь по весам для модели линейной регрессии:\n",
    "$$ \\nabla_w L = \\dots $$\n",
    "Как соотносится этот градиент с градиентом, возникающий в задаче логистической регресии? Вас это удивило, Вы это уже раньше заметили или Вам все равно? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Ваше решение здесь***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\frac{dL}{dw^k} = \\frac{2}{N}\\sum_i x_{i}^k(a_i-y_i)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>При стремлении вероятности к 1(0) градиент логистической функции потерь сходится к градиенту фп линейной регрессии"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задача 4.  Предсказываем вероятности.\n",
    "\n",
    "Когда говорят о логистической регрессии, произносят фразу, что она \"предсказывает вероятности положительного класса\". Давайте разберемся, что же за этим стоит. Посчитаем математическое ожидание функции потерь и проверим, что предсказание алгоритма, оптимизирующее это мат. ожидание, будет являться вероятностью положительного класса. \n",
    "\n",
    "И так, функция потерь на объекте $x_i$, который имеет метку $y_i \\in \\{0,1\\}$  для предсказания $a(x_i)$ равна:\n",
    "$$L(y_i, b) =-[y_i == 1] \\log a(x_i)  - [y_i == 0] \\log(1 - a(x_i)) $$\n",
    "\n",
    "Где $[]$ означает индикатор $-$ он равен единице, если значение внутри него истинно, иначе он равен нулю. Тогда мат. ожидание при условии конкретного $x_i$  по определение мат. ожидания дискретной случайной величины:\n",
    "$$E(L | x_i) = -p(y_i = 1 |x_i ) \\log a(x_i)  - p(y_i = 0 | x_i) \\log( 1 - a(x_i))$$\n",
    "* Докажите, что значение $a(x_i)$, минимизирующее данное мат. ожидание, в точности равно $p(y_i = 1 |x_i)$, то есть равно вероятности положительного класса.\n",
    "\n",
    "Подсказка: возможно, придется воспользоваться, что  $p(y_i = 1 | x_i) + p(y_i = 0 | x_i) = 1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\frac {dE(L | x_i)}{da(x_i)} = - \\frac{p(y_i = 1 |x_i )}{a(x_i)}  + \\frac{p(y_i = 0 | x_i)}{1 - a(x_i)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ - \\frac{p(y_i = 1 |x_i )}{a(x_i)}  + \\frac{p(y_i = 0 | x_i)}{1 - a(x_i)} = 0$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ p(y_i = 1 |x_i )(1-a(x_i))  - p(y_i = 0 | x_i)a(x_i) = 0$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ a(x_i) = p(y_i = 1 | x_i) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Реализация логистической регрессии (6 баллов)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Зачем нужны батчи?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как Вы могли заметить из теоретического введения, что в случае SGD, что в случа mini-batch GD,  на каждой итерации обновление весов  происходит только по небольшой части данных (1 пример в случае SGD, batch примеров в случае mini-batch). То есть для каждой итерации нам *** не нужна вся выборка***. Мы можем просто итерироваться по выборке, беря батч нужного размера (далее 1 объект тоже будем называть батчом).\n",
    "\n",
    "Легко заметить, что в этом случае нам не нужно загружать все данные в оперативную память, достаточно просто считать батч с диска, обновить веса, считать диска другой батч и так далее. В целях упрощения домашней работы, прямо с диска  мы считывать не будем, будем работать с обычными numpy array. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Немножко про генераторы в Python\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Идея считывания данных кусками удачно ложится на так называемые ***генераторы*** из языка Python. В данной работе Вам предлагается не только разобраться с логистической регрессией, но  и познакомиться с таким важным элементом языка.  При желании Вы можете убрать весь код, связанный с генераторами, и реализовать логистическую регрессию и без них, ***штрафоваться это никак не будет***. Главное, чтобы сама модель была реализована правильно, и все пункты были выполнены. \n",
    "\n",
    "Подробнее можно почитать вот тут https://anandology.com/python-practice-book/iterators.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "К генератору стоит относиться просто как к функции, которая порождает не один объект, а целую последовательность объектов. Новое значение из последовательности генерируется с помощью ключевого слова ***yield***. Ниже Вы можете насладиться  генератором чисел Фибоначчи."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fib(max_iter=4):\n",
    "    a, b = 0, 1\n",
    "    iter_num = 0\n",
    "    while 1:\n",
    "        yield a\n",
    "        a, b = b, a + b\n",
    "        iter_num += 1\n",
    "        if iter_num == max_iter:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вот так можно сгенерировать последовательность Фибоначчи. \n",
    "\n",
    "Заметьте, что к генераторам можно применять некоторые стандартные функции из Python, например enumerate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fib num: 0 fib values: 0\n",
      "Fib num: 1 fib values: 1\n",
      "Fib num: 2 fib values: 1\n",
      "Fib num: 3 fib values: 2\n"
     ]
    }
   ],
   "source": [
    "new_generator = fib()\n",
    "for j, fib_val in enumerate(new_generator):\n",
    "    print (\"Fib num: \" + str(j) + \" fib values: \" + str(fib_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пересоздавая объект, можно сколько угодно раз генерировать заново последовательность. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fib num: 0 fib values: 0\n",
      "Fib num: 1 fib values: 1\n",
      "Fib num: 2 fib values: 1\n",
      "Fib num: 3 fib values: 2\n",
      "Fib num: 0 fib values: 0\n",
      "Fib num: 1 fib values: 1\n",
      "Fib num: 2 fib values: 1\n",
      "Fib num: 3 fib values: 2\n",
      "Fib num: 0 fib values: 0\n",
      "Fib num: 1 fib values: 1\n",
      "Fib num: 2 fib values: 1\n",
      "Fib num: 3 fib values: 2\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 3):\n",
    "    new_generator = fib()\n",
    "    for j, fib_val in enumerate(new_generator):\n",
    "        print (\"Fib num: \" + str(j) + \" fib values: \" + str(fib_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А вот так уже нельзя."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fib num: 0 fib values: 0\n",
      "Fib num: 1 fib values: 1\n",
      "Fib num: 2 fib values: 1\n",
      "Fib num: 3 fib values: 2\n"
     ]
    }
   ],
   "source": [
    "new_generator = fib()\n",
    "for i in range(0, 3):\n",
    "    for j, fib_val in enumerate(new_generator):\n",
    "        print (\"Fib num: \" + str(j) + \" fib values: \" + str(fib_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Концепция крайне удобная для обучения  моделей $-$ у Вас есть некий источник данных, который Вам выдает их кусками, и Вам совершенно все равно откуда он их берет. Под ним может скрывать как массив в оперативной памяти, как файл на жестком диске, так и SQL база данных. Вы сами данные никуда не сохраняете, оперативную память экономите."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если Вам понравилась идея с генераторами, то Вы можете реализовать свой, используя прототип batch_generator. В нем Вам нужно выдавать батчи признаков и ответов для каждой новой итерации спуска. Если не понравилась идея, то можете реализовывать SGD или mini-batch GD без генераторов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_generator(X, y, shuffle=True, batch_size=2):\n",
    "    \"\"\"\n",
    "    Гератор новых батчей для обучения\n",
    "    X          - матрица объекты-признаки\n",
    "    y_batch    - вектор ответов\n",
    "    shuffle    - нужно ли случайно перемешивать выборку\n",
    "    batch_size - размер батча ( 1 это SGD, > 1 mini-batch GD)\n",
    "    Генерирует подвыборку для итерации спуска (X_batch, y_batch)\n",
    "    \"\"\"\n",
    "    n_batches = X.shape[0] // batch_size\n",
    "    for i in range(n_batches):\n",
    "        mask = np.random.permutation(X.shape[0])[:batch_size]\n",
    "        X_batch, y_batch = X[mask], y[mask]\n",
    "        yield (X_batch, y_batch)\n",
    "\n",
    "# Теперь можно сделать генератор по данным ()\n",
    "#  my_batch_generator = batch_generator(X, y, shuffle=True, batch_size=1):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%pycodestyle\n",
    "\n",
    "def sigmoid(X):\n",
    "    \"\"\"\n",
    "    Вычисляем значение сигмоида.\n",
    "    X - матрица объекты-признаки\n",
    "    \"\"\"\n",
    "    return 1 / (1 + np.exp(-X))\n",
    "\n",
    "\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "\n",
    "class MySGDClassifier(BaseEstimator, ClassifierMixin):\n",
    "    \"\"\"\n",
    "    Предполагается, что в выборке всегда 2 класса\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, batch_generator, C=1, alpha=0.01, max_epoch=10):\n",
    "        \"\"\"\n",
    "        batch_generator -- функция генератор, которой будем создавать батчи\n",
    "        C - коэф. регуляризации\n",
    "        alpha - скорость спуска\n",
    "        max_epoch - максимальное количество эпох\n",
    "        \"\"\"\n",
    "        \n",
    "        self.C = C\n",
    "        self.alpha = alpha\n",
    "        self.max_epoch = max_epoch\n",
    "        self.batch_generator = batch_generator\n",
    "        self.errors_log = {'iter' : [], 'loss' : []}\n",
    "        \n",
    "    def calc_loss(self, X_batch, y_batch):\n",
    "        \"\"\"\n",
    "        Считаем функцию потерь по батчу \n",
    "        X_batch - матрица объекты-признаки по батчу\n",
    "        y_batch - вектор ответов по батчу\n",
    "        \"\"\"\n",
    "        a = sigmoid(X_batch.dot(self.weights))\n",
    "        R = np.sum(self.weights**2)/self.C\n",
    "        N = X_batch.shape[0]\n",
    "        return -(1/N)*np.sum(y_batch*np.log(a)+(1-y_batch)*np.log(1-a))+R\n",
    "    \n",
    "    def calc_loss_grad(self, X_batch, y_batch):\n",
    "        \"\"\"\n",
    "        Считаем  градиент функции потерь по батчу (то что Вы вывели в задании 1)\n",
    "        X_batch - матрица объекты-признаки по батчу\n",
    "        y_batch - вектор ответов по батчу\n",
    "        \"\"\"\n",
    "        a = sigmoid(X_batch.dot(self.weights))\n",
    "        N = X_batch.shape[0]\n",
    "        return (1/N)*(a-y_batch).dot(X_batch)+(2/self.C)*self.weights\n",
    "    \n",
    "    def update_weights(self, new_grad):\n",
    "        \"\"\"\n",
    "        Обновляем вектор весов\n",
    "        new_grad - градиент по батчу\n",
    "        \"\"\"\n",
    "        self.weights -= self.alpha*new_grad\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        '''\n",
    "        Обучение модели\n",
    "        X - матрица объекты-признаки\n",
    "        y - вектор ответов\n",
    "        '''\n",
    "        X = np.hstack((np.ones((X.shape[0], 1)), X))\n",
    "        self.weights = np.random.uniform(0, 1, X.shape[1])\n",
    "        for n in range(0, self.max_epoch):\n",
    "            new_epoch_generator = self.batch_generator(X, y)\n",
    "            for batch_num, new_batch in enumerate(new_epoch_generator):\n",
    "                X_batch = new_batch[0]\n",
    "                y_batch = new_batch[1]\n",
    "                batch_grad = self.calc_loss_grad(X_batch, y_batch)\n",
    "                self.update_weights(batch_grad)\n",
    "                # Подумайте в каком месте стоит посчитать ошибку для отладки модели\n",
    "                # > После шага градиентного спуска посчитайте \n",
    "                # значение ошибки на объекте \n",
    "                batch_loss = self.calc_loss(X_batch, y_batch)\n",
    "                self.errors_log['iter'].append(batch_num)\n",
    "                self.errors_log['loss'].append(batch_loss)\n",
    "                \n",
    "        return self\n",
    "        \n",
    "    def predict(self, X):\n",
    "        '''\n",
    "        Предсказание класса\n",
    "        X - матрица объекты-признаки\n",
    "        '''\n",
    "        \n",
    "        # Желательно здесь использовать матричные операции между X и весами, например, numpy.dot\n",
    "        return (self.predict_proba(X)>=0.5).astype(int)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        '''\n",
    "        Предсказание вероятности положительного класса\n",
    "        X - матрица объекты-признаки\n",
    "        '''\n",
    "        X = np.hstack((np.ones((X.shape[0], 1)), X))\n",
    "        y_hat_proba = sigmoid(X.dot(self.weights))\n",
    "        # Желательно здесь использовать матричные операции между X и весами, например, numpy.dot \n",
    "        return y_hat_proba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запустите ваш алгоритм на синтетических данных. \n",
    "\n",
    "Выведите полученные веса и нарисуйте разделяющую границу между классами (используйте только первых два веса для первых двух признаков X[:,0], X[:,1] для отображения в 2d пространство ).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_decision_boundary(clf):\n",
    "    ## Your code Here\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0xa1f81b4e0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "C1 = np.array([[0., -0.8], [1.5, 0.8]])\n",
    "C2 = np.array([[1., -0.7], [2., 0.7]])\n",
    "gauss1 = np.dot(np.random.randn(200, 2) + np.array([5, 3]), C1)\n",
    "gauss2 = np.dot(np.random.randn(200, 2) + np.array([1.5, 0]), C2)\n",
    "\n",
    "X = np.vstack([gauss1, gauss2])\n",
    "y = np.r_[np.ones(200), np.zeros(200)]\n",
    "\n",
    "# plot_decision_boundary(your_model)\n",
    "\n",
    "plt.scatter(X[:,0], X[:,1], c=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее будем анализировать Ваш алгоритм. \n",
    "Для этих заданий используйте датасет ниже."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, y = make_classification(n_samples=100000, n_features=10, \n",
    "                           n_informative=4, n_redundant=0, \n",
    "                           random_state=123, class_sep=1.0,\n",
    "                           n_clusters_per_class=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Покажите сходимость вашего метода на этом датасете: изобразите график  функции потерь, усредненной по $N$ шагам градиентого спуска, для разных `alpha` (размеров шага). Разные `alpha` расположите на одном графике. \n",
    "\n",
    "$N$ можно брать 10, 50, 100 и т.д. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Your Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что Вы можете сказать про сходимость метода при различных `alpha`? Какое значение стоит выбирать для лучшей сходимости?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Изобразите график среднего значения весов модели в зависимости от коеф. регуляризации С из `np.logspace(3, -3, 10)` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Your Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Довольны ли Вы, насколько сильно уменьшились Ваши веса? Если нет, то как можно было бы уменьшать их еще сильнее?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Боевое применение (2  балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## О hearthstone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Hearthstone](http://eu.battle.net/hearthstone/ru/) - карточная онлайн игра по мотивам вселенной Warcraft.\n",
    "\n",
    "Каждый игрок играет за персонажа определенного класса и собирает колоду карт которую может разыгрывать во время игры. Для дальнейших деталей обратитесь к [wiki](https://ru.wikipedia.org/wiki/Hearthstone), посмотрите youtube или поиграйте сами (но не долго =) ).\n",
    "\n",
    "Теми или иными способами игрок может отнимать жизни у своего оппонента, таким образом цель раунда - побить другого игрока."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src='http://ps3hits.ru/wp-content/uploads/2015/08/hearthstone-game-sshot-1.jpg'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Постановка задачи"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В рамках конференции [AAIA 17](https://fedcsis.org/2017/aaia) было запущено [соревнование](https://knowledgepit.fedcsis.org/contest/view.php?id=120) по предсказанию исхода раунда в heartstone. \n",
    "\n",
    "Используя признаки, которые описывают текущее состояние раунда необходимо предсказать **вероятность** победы игрока в этом раунде.\n",
    "\n",
    "Качество модели измеряется с помощью **ROC-AUC**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Данные\n",
    "\n",
    "Обучающую выборку и тестовую выборку с ответами можно скачать [отсюда](https://cloud.mail.ru/public/BEon/4Rrdqqvng)\n",
    "\n",
    "Данные содержат набор информации о раунде в некоторый момент времени: жизни игрока и оппонента, номер хода, карты на столе, карты в руке игрока, количество карт в руке оппонента и тп.<br/>\n",
    "По игроку №1 (далее просто **игрок**) помимо всего прочего известен набор карт \"в руке\".</br>\n",
    "По игроку №2 (далее просто **оппонент**) эта информация отсутствует.</br>\n",
    "\n",
    "\n",
    "В данных для обучению содержится 2 млн. игр, разбитых на 4 файла. Названия признаков говорят сами за себя.\n",
    "Целевой признак - `decision` (1 - победил игрок, 0 - победил оппонент)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Загрузка данных для обучения\n",
    "filepath = 'trainingData_tabular/trainingData_tabular_chunk1.csv'\n",
    "df_data = pd.read_csv(filepath, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gamestate_id</th>\n",
       "      <th>decision</th>\n",
       "      <th>turn</th>\n",
       "      <th>opponent.armor</th>\n",
       "      <th>opponent.attack</th>\n",
       "      <th>opponent.hero_card_id</th>\n",
       "      <th>opponent.hp</th>\n",
       "      <th>opponent.special_skill_used</th>\n",
       "      <th>opponent.weapon_durability</th>\n",
       "      <th>opponent.crystals_all</th>\n",
       "      <th>...</th>\n",
       "      <th>player.played.hp_current</th>\n",
       "      <th>player.played.hp_max</th>\n",
       "      <th>player.hand.nOfMinions</th>\n",
       "      <th>player.hand.nOfSpells</th>\n",
       "      <th>player.hand.nOfWeapons</th>\n",
       "      <th>player.hand.nOfCards</th>\n",
       "      <th>player.hand.nOfPlayable</th>\n",
       "      <th>player.hand.attack</th>\n",
       "      <th>player.hand.crystals_cost</th>\n",
       "      <th>player.hand.hp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4687346</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>798</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>22</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3270826</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>754</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>26</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3189487</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>612</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>28</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4098946</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>390</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>36</td>\n",
       "      <td>44</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2661127</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   gamestate_id  decision  turn  opponent.armor  opponent.attack  \\\n",
       "0       4687346         1    14               0                0   \n",
       "1       3270826         1     7               0                0   \n",
       "2       3189487         1     5               3                0   \n",
       "3       4098946         1     8               0                0   \n",
       "4       2661127         0    13               0                0   \n",
       "\n",
       "   opponent.hero_card_id  opponent.hp  opponent.special_skill_used  \\\n",
       "0                    798            5                            0   \n",
       "1                    754           22                            0   \n",
       "2                    612           29                            0   \n",
       "3                    390           26                            0   \n",
       "4                     25           30                            0   \n",
       "\n",
       "   opponent.weapon_durability  opponent.crystals_all       ...        \\\n",
       "0                           0                     10       ...         \n",
       "1                           0                      6       ...         \n",
       "2                           0                      4       ...         \n",
       "3                           0                      7       ...         \n",
       "4                           0                     10       ...         \n",
       "\n",
       "   player.played.hp_current  player.played.hp_max  player.hand.nOfMinions  \\\n",
       "0                        20                    23                       4   \n",
       "1                        16                    17                       3   \n",
       "2                         0                     0                       5   \n",
       "3                         2                     2                       7   \n",
       "4                         7                     7                       4   \n",
       "\n",
       "   player.hand.nOfSpells  player.hand.nOfWeapons  player.hand.nOfCards  \\\n",
       "0                      0                       1                     5   \n",
       "1                      2                       2                     7   \n",
       "2                      0                       0                     5   \n",
       "3                      1                       1                     9   \n",
       "4                      0                       0                     4   \n",
       "\n",
       "   player.hand.nOfPlayable  player.hand.attack  player.hand.crystals_cost  \\\n",
       "0                        0                  20                         22   \n",
       "1                        0                  17                         26   \n",
       "2                        2                  26                         28   \n",
       "3                        9                  36                         44   \n",
       "4                        4                  13                         13   \n",
       "\n",
       "   player.hand.hp  \n",
       "0              17  \n",
       "1              20  \n",
       "2              27  \n",
       "3              36  \n",
       "4              14  \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# для удобства\n",
    "df_data.columns = df_data.columns.str.replace('.', '_')\n",
    "df_data = df_data.set_index('gamestate_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_data.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Распределение классов\n",
    "df_data.decision.mean()\n",
    "# Примерно поровну"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Получите матрицу объект признак `X` и вектор целевого признака `y`\n",
    "* Преобразуйте категориальные переменные с помощью one-hot кодирования, добавьте к датасету и удалите прежние столбцы. (Вы точно понимаете, зачем это нужно сделать? Если нет, спросите обязательно преподавателя!)\n",
    "* Стандартизируйте признаки с помощью `StandartScaller` из sklearn (Вы точно понимаете, зачем это нужно сделать? Если нет, спросите обязательно преподавателя!)\n",
    "* Обучите модель, подбирая параметры на отложенном контроле"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Youd Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Применение модели \n",
    "* Подготовьте тестовые данные  к подаче на вход в алгоритму (нужно сделать такие же преобразования, как при обучении)\n",
    "* Примените модель оцените качество на тесте с помощью меры ROC-AUC (имплментацию взять из sklern.metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Загрузка данных для тестирования\n",
    "filepath_test = 'trainingData_tabular/trainingData_tabular_chunk2.csv'\n",
    "df_data_test = pd.read_csv(filepath_test, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Youd Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Контрольные вопросы\n",
    "Постарайтесь максимально развернуто и честно ответить на вопросы. Они охватывают тему линейных моделей и скорее нужны преподавателям, чтобы понимать, что именно Вы усвоили плохо. Надеюсь, они подскажут, что именно в теме Вы не понимаете или наоборот порадают, что Вы все знаете ^_^"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Опишите основные, на Ваш взгляд,  отличия логистической регрессии от линейной регрессии. Почему, на ваш взгляд, задачу классификации решают логистической, а не линейной регрессией?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Ваше ответ здесь***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Как Вы думаете, для каких типов задач (объем данных, число признаков, типы признаков) стоит отдавать предпочтение линейным моделям?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Ваше ответ здесь***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Пусть на обучении мы имеем выборку размера $N$, число признаков $D$. Чему равна алгоритмическая сложность одного шага градиентного спуска? Cтохастического градиентного спуска?  Сложность предсказания на одном объекте?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Ваше ответ здесь***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* В чем преимущества стохастического градиентного спуска (в том числе мини-батч) над обычным градиентным спуском? В чем его недостатки? Рассмотрите несколько аспектов $-$ скорость сходимости, необходимость загрузки всех данных в оперативную память, сложность вычисления одного шага."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Ваше ответ здесь***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Как Вы думаете, при обучении линейной модели с помощью SGD, ошибку на новом объекте стоит считать до итерации спуска на этом объекте или после? Почему Вы так думаете? Возможно, Вам будет интересно ознакомиться с http://hunch.net/~jl/projects/prediction_bounds/thesis/mathml/thesisse44.xml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Ваше ответ здесь***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Как Вы думаете, во времена такого бума нейронных сетей, остаются ли популярными линейные модели, или это уже пережиток прошлого? Почему Вы так думаете?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Ваше ответ здесь***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Какие аспекты обучения линейных моделей Вам показались непонятными? Какое место стоит дополнительно объяснить?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Ваше ответ здесь***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь Вы можете оставить отзыв о этой домашней работе или о всем курсе.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** ВАШ ОТЗЫВ ЗДЕСЬ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "nav_menu": {},
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "402px",
    "width": "253px"
   },
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": true,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
